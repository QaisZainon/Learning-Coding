#Web Scraping is essentially a program to download and process content from the web

#webbrowser Comes with python and opens a browser to a specific page
#requests Downloads files and web pages from the internet
#bs4 Parses HTML, the format that web pages are written in
#selenium Launches and controls a web browser. Can also fill in forms and simulate mouse clicks in browser

#import webbrowser
#webbrowser.open('https://inventwithpython.com/')
#the module's open function that opens an url

#import requests #can be used to download webpages
#v=requests.get('')
#v.status_code == requests.codes.ok #checks whether the web is actually accessible or not
#it actually checks whether the HTML code has an interger of 200

#res.raise_for_status() #raises an exception whenever a bad download happens
#can use it to halt a program for bad download or pair it with try & except

#to write in files, youll need to open with 'wb'(write binary) as the second argument
#before .write(), youll first need to loop through chunks
#eg.for chunk in v.iter_content(100000):
#    playFile.write(chunk)
#its to ensure that the requests module doesnt eat up too much memory 

#right click on the web to view sourcode
#right click to inspect the specfic line you want, and the web developer window will open
#Right click on the line you want to copy and copy with css selector

#import bs4 #bs4 stands for beautiful soup 4
#scrape information from webpages, usually needs either a HTML or XML parser
#exampleFile = open('example.html')
#exampleSoup = bs4.BeautifulSoup(exampleFile, 'html.parser')

#CSS selectors
#soup.select('div') #All elements named <div>
#soup.select('#author') #The element with an id attribute of author
#soup.select('.notice') #All elements that use a CSS class attribute named notice
#soup.select('div span') #All elements named <span> that are within an element named <div>
#soup.select('div > span') #All elements named <span> that are directly within an element named <div>, with no other element in between
#soup.select('input[name]') #All elements named <input> that have a name attribute with any value
#soup.select('input[type="button"]') #All elements named <input> that have an attribute named type with value button
#usually you just copy using css selector from inspect element
#can also put 'p' as the argument in the select to parse all the <p></p>

#v.attrs #returns Tag value and the value???

#can use get method for Tag objects
#v.getText()
#v.get('tag')

#I dont understand anything lol

#Selenium Module
#lets python directly control the browser by clicking links and filling in login information
#sites have systems in place of deny scripts from harvesting data
#selenium lets it function, but its still blocked by some websites
#from selenium import webdriver #idk why but it do be like that
#v=webdriver.Firefox() #opens the browser using the driver
#browser.get('link') #to open the website using the browser

#find_alement* #finds only the first WebElement that matches
#find_elements* #returns a list of WebElement for every matchs

#Methods
#add s at the end of element for multiple returns
#browser.find_element_by_class_name(name) #Elements that use the CSS class name
#browser.find_element_by_css_selector(selector) #Elements that match the CSS selector
#browser.find_element_by_id(id) #Elements with a matching id attribute value
#browser.find_element_by_link_text(text) #<a> elements that completely match the text provided
#browser.find_element_by_partial_link_text(text) #<a> elements that contain the text provided
#browser.find_element_by_name(name) #Elements with a matching name attribute
#browser.find_element_by_tag_name(name) #Elements with a matching tag name, no case sensitive

#if no elements in the page selenium will raise a NoSuchElement exception, can just try except to circumvent this

#Attribute or Method for the WebElement
#tag_name #The tag name, such as 'a' for an <a> element
#get_attibute(name) #The value for the elemnt's name attribute
#text #The text within the elemnt, such as 'hello in <span>hello </span>
#clear() #For text field or text area elements, clears the text typed into it
#is_displayed() #Returns True if the element is visible; otherwise returns False
#is_enabled() #For input elements, returns True if the elements is enabled; otherwise returns False
#is_selected() #For checkbox or radio button elements, returns True if the element is selcted; otherwise returns False
#location #A dictionary with keys 'x' and 'y' for the position of the elemnt in the page

#objects returned have a .click() method thats similar to a mouse click

#you can send shit into text boxes using .send_keys onto a variable with .browser_find*
#Calling .submit() method on any element will have the same result as clicking the submit button

#Selenium can also input keys into the webbrowser
#from selenium.webdriver.common.keys import Keys
#need to add .send_keys(), the arugment is in the method
#Keys.DOWN
#Keys.UP
#Keys.LEFT
#Keys.RIGHT
#Keys.ENTER
#Keys.RETURN
#Keys.HOME
#Keys.END
#Keys.PAGE_DOWN
#Keys.PAGE_UP
#Keys.ESCAPE
#Keys.BACK_SPACE
#Keys.DELETE
#Keys.F1,...,Keys.F12
#Keys.TAB

#Selenium can also click on the browser buttons 
#browser.back() #Clicks the Back button
#browser.forward() Clicks the Forward button
#browser.refresh() CLicks the Refresh/Reload button
#browser.quit() Clicks the Close Window button

#https://selenium-python.readthedocs.org/